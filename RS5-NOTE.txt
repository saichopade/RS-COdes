import numpy as np
import pandas as pd

# Step 1: Load the dataset (you would typically use pd.read_csv to load a CSV file,
# but since you provided it in text form, we'll assume it's already loaded into a DataFrame).

# Example DataFrame 
data = pd.read_csv('/content/drive/MyDrive/RS Practical 5/Womens Clothing E-Commerce Reviews.csv')

data.dropna(inplace=True)
data.drop(['Unnamed: 0'], axis=1, inplace=True)
data.head()


# Step 2: Create a user-item interaction matrix
# We will assume each user is uniquely represented by their 'Age' and Clothing ID as items.

# Assign each unique clothing item to a column
clothing_items = df['Clothing ID'].unique()
users = df['Age'].unique()

# Create a mapping from clothing items to indices
item_index = {item: idx for idx, item in enumerate(clothing_items)}
user_index = {user: idx for idx, user in enumerate(users)}

# Initialize the user-item interaction matrix (ratings matrix)
user_item_matrix = np.zeros((len(users), len(clothing_items)))

# Populate the user-item matrix with ratings
for _, row in df.iterrows():
    user_idx = user_index[row['Age']]
    item_idx = item_index[row['Clothing ID']]
    user_item_matrix[user_idx, item_idx] = row['Rating']

# Step 3: Matrix factorization using gradient descent
num_users, num_items = user_item_matrix.shape
num_factors = 2  # Latent factors
alpha = 0.01     # Learning rate
num_epochs = 100
lambda_reg = 0.02  # Regularization parameter

# Initialize user and item latent factor matrices with random values
user_factors = np.random.rand(num_users, num_factors)
item_factors = np.random.rand(num_items, num_factors)

# Step 4: Perform matrix factorization using Gradient Descent
for epoch in range(num_epochs):
    for i in range(num_users):
        for j in range(num_items):
            if user_item_matrix[i, j] > 0:  # Only update for existing ratings
                # Calculate the prediction error for user i and item j
                prediction = np.dot(user_factors[i, :], item_factors[j, :].T)
                error = user_item_matrix[i, j] - prediction

                # Update user and item latent factors
                user_factors[i, :] += alpha * (error * item_factors[j, :] - lambda_reg * user_factors[i, :])
                item_factors[j, :] += alpha * (error * user_factors[i, :] - lambda_reg * item_factors[j, :])

    # Calculate the total error every 1000 epochs for monitoring
    if epoch % 10 == 0:
        total_error = 0
        for i in range(num_users):
            for j in range(num_items):
                if user_item_matrix[i, j] > 0:
                    prediction = np.dot(user_factors[i, :], item_factors[j, :].T)
                    total_error += (user_item_matrix[i, j] - prediction) ** 2
        print(f"Epoch {epoch}, Total Error: {total_error/10000:.4f}")

# Step 5: Predict missing values for recommendations
predicted_matrix = np.dot(user_factors, item_factors.T)
print("\nPredicted User-Item Matrix:")
print(predicted_matrix)

# Step 6: Recommend items for a specific user
user_id = 0  # Example user
# Recommend top 2 items that user hasn't interacted with
user_ratings = user_item_matrix[user_id]
predicted_ratings = predicted_matrix[user_id]
recommendations = np.argsort(predicted_ratings - user_ratings)  # Sort by predicted rating

# Only recommend items not yet interacted with
recommended_items = [i for i in recommendations if user_ratings[i] == 0][:2]
print(f"\nTop recommendations for User {user_id} (Age {users[user_id]}): Clothing Item IDs {clothing_items[recommended_items]}")


!pip install scikit-surprise


import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_squared_error

# Assuming 'data' is your original dataframe
df = data.copy()

# Step 1: Adjust index to start from 2 and create the 'user_id' column
df['user_id'] = df.index  # Use the current index as the user_id
df['user_id'] = df['user_id'] + 2  # Adjust index so it starts from 2

# Step 2: Create the user-item interaction matrix (pivot table)
# Using 'user_id' for the index and 'Clothing ID' for the columns
interaction_matrix = df.pivot_table(index='user_id', columns='Clothing ID', values='Rating', fill_value=0)

# Step 3: Apply SVD (Singular Value Decomposition) - Matrix factorization technique
svd = TruncatedSVD(n_components=2)  # Use 2 components, adjust for better performance if needed
latent_matrix = svd.fit_transform(interaction_matrix)

# Step 4: Reconstruct the approximation of the original matrix
approx_matrix = np.dot(latent_matrix, svd.components_)

# Step 5: Calculate RMSE (Root Mean Square Error) for prediction accuracy
# We need to compare the predicted values with actual ratings
# Flatten both the original and approximated matrices for comparison
original_matrix_flat = interaction_matrix.values.flatten()
approx_matrix_flat = approx_matrix.flatten()

# Mask the zero entries in the interaction matrix (because they represent missing values)
mask = original_matrix_flat != 0
rmse = np.sqrt(mean_squared_error(original_matrix_flat[mask], approx_matrix_flat[mask]))
print("Root Mean Square Error (RMSE):", rmse)

# Step 6: Making Recommendations for a specific user
user_id = 5  # Example user, can be any user_id from your dataset
if user_id not in interaction_matrix.index:
    print(f"User {user_id} not found.")
else:
    user_row_index = interaction_matrix.index.get_loc(user_id)  # Find the row index for the user

    # Predict the ratings for items the user hasn't rated yet
    unrated_items = interaction_matrix.iloc[user_row_index] == 0  # Find unrated items
    predicted_ratings = approx_matrix[user_row_index]

    # Get predictions for unrated items
    recommendations = []
    for i, unrated in enumerate(unrated_items):
        if unrated:  # If the item is unrated
            recommendations.append((interaction_matrix.columns[i], predicted_ratings[i]))

    # Sort by predicted rating and recommend the top items
    recommendations.sort(key=lambda x: x[1], reverse=True)
    top_recommendations = recommendations[:3]  # Top 3 recommendations
    print(f"Top Recommendations for User {user_id}: {top_recommendations}")



The acj_rs_assgn_5.py script demonstrates a recommendation system for an e-commerce platform using techniques like Matrix Factorization (SVD) and Gradient Descent. The system focuses on recommending clothing items to users based on their past interactions (ratings). Here's a detailed explanation:

1. Dataset and Overview
The dataset contains reviews from a women’s clothing e-commerce platform, with the following fields:
    Clothing ID: Unique identifier for each clothing item.
    Age: User's age (used to identify users uniquely).
    Rating: User's rating for the clothing item (1–5).
This dataset is processed into a User-Item Interaction Matrix to represent ratings given by users to items.

2. Data Preparation
Dataset Loading:
The dataset is loaded using pd.read_csv and cleaned:
    Missing values are dropped using dropna.
    Unnecessary columns (e.g., Unnamed: 0) are removed.

User-Item Interaction Matrix:
    Rows represent users (identified by Age).
    Columns represent clothing items (identified by Clothing ID).
    Each cell contains the rating given by a user to an item (or 0 if no rating exists).

Steps:

1 Unique Users and Items:
Extract unique values for Age and Clothing ID.
2 Index Mapping:
Create mappings for users and items to assign matrix indices.
3 Matrix Creation:
Initialize a matrix of zeros.
Populate the matrix with ratings from the dataset.

3. Matrix Factorization Using Gradient Descent
Matrix Factorization decomposes the User-Item Matrix into two smaller matrices:
1 User Factors (Latent Features): Represent preferences of each user.
2 Item Factors (Latent Features): Represent characteristics of each item.

Steps for Factorization:
step 1 -> Initialization:
Randomly initialize user and item matrices with latent features (num_factors = 2).
step 2 -> Error Calculation:

For each non-zero rating in the matrix, calculate the prediction error:
Error=Actual Rating−Predicted Rating
where:
Predicted Rating=Dot Product of User Factors and Item Factors

step 3 ->Gradient Descent Update:
Update user and item factors to minimize the error:
User Factors Update: 𝑈𝑖←𝑈𝑖+𝛼(Error⋅𝐼𝑗−𝜆⋅𝑈𝑖)
Item Factors Update: 𝐼𝑗←𝐼𝑗+𝛼(Error⋅𝑈𝑖−𝜆⋅𝐼𝑗)
where:
α: Learning rate.
λ: Regularization parameter to prevent overfitting.

step 4 ->Convergence Check:
The total error across all ratings is calculated every 10 epochs to monitor progress.

4. Making Recommendations
Prediction:
`After training, the predicted ratings matrix is reconstructed by multiplying the user and item factors:    Predicted Matrix=U⋅I^T
`This matrix contains predicted ratings for all users and items, including unrated items.

Recommendations for a User:
For a specific user:
    Identify items the user hasn’t rated yet.
    Sort these items by predicted rating in descending order.
    Recommend the top N items.


5. Evaluation
Error Monitoring:
Root Mean Square Error (RMSE) is used to measure prediction accuracy:
RMSE= all underroot (1/n ∑(Actual Rating−Predicted Rating)^2)
  
Example Output:
Epoch 10, Total Error: 0.2431
Epoch 20, Total Error: 0.1987
Root Mean Square Error (RMSE): 0.567


6. SVD-Based Recommendations
In addition to Gradient Descent, the script demonstrates Singular Value Decomposition (SVD):
1 Apply SVD:
Decomposes the User-Item Matrix into latent factors using TruncatedSVD.
2 Reconstruction:
Approximates the original matrix by combining the latent factors.
3 Error Calculation:
RMSE is calculated for the reconstructed matrix.


7. Practical Implementation
During the practical examination, you might demonstrate:

Matrix Factorization:
    Explain the initialization of latent factors.
    Discuss how gradient descent is used to minimize prediction error.

Predicted Ratings:
Show the reconstructed matrix and compare it with the original ratings.

Recommendations:
Recommend top items for a specific user.
---Example output:
Top Recommendations for User 0 (Age 25): Clothing Item IDs [1001, 1005]


8. Key Concepts for Examination

A. Matrix Factorization
Understand the decomposition process:
User-Item Matrix =U⋅I^T
Explain how latent features represent hidden patterns in user preferences and item characteristics.

B. Gradient Descent
Explain the iterative process:
Updating user and item factors.
Minimizing error through learning rate and regularization.

C. Recommendations
Discuss how predictions for unrated items are made.
Highlight how recommendations are personalized.

D. Evaluation
Importance of RMSE as an error metric.
How RMSE indicates the model's predictive accuracy.



9. Applications
This project illustrates practical applications of recommendation systems:
E-commerce:
Recommending products based on user preferences and interactions.
Scalability:
The matrix factorization approach can handle large datasets effectively


